{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb6a83c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 47 regions had no data and were excluded.\n",
      "Final matrix saved to:\n",
      "Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\PE_mapping\\processed_data\\dff_downsampled\\collapsed_region_matrix.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "\n",
    "# === CONFIG ===\n",
    "structures_csv = r\"Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\code\\cfos_preprocessing\\allen_mouse_10um_v1.2\\structures.csv\"\n",
    "category_csv = r\"Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\PE_mapping\\processed_data\\pe_grouped.csv\"\n",
    "input_excel = r\"Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\PE_mapping\\processed_data\\dff_downsampled\\mean_dff_per_region_by_mouse_brainmapper.xlsx\"\n",
    "output_file = r\"Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\PE_mapping\\processed_data\\dff_downsampled\\collapsed_region_matrix.xlsx\"\n",
    "target_n_regions = 160\n",
    "\n",
    "# === LOAD REGION HIERARCHY ===\n",
    "region_table = pd.read_csv(structures_csv)\n",
    "region_table['structure_id_path'] = region_table['structure_id_path'].astype(str)\n",
    "\n",
    "# Build graph from structure_id_path\n",
    "G = nx.DiGraph()\n",
    "for _, row in region_table.iterrows():\n",
    "    path = row[\"structure_id_path\"].strip(\"/\").split(\"/\")\n",
    "    for i in range(len(path) - 1):\n",
    "        G.add_edge(path[i], path[i + 1])\n",
    "\n",
    "# === COLLAPSE TREE TO ~130 REGIONS (STRUCTURE ONLY) ===\n",
    "def collapse_tree_to_n(graph, n_regions):\n",
    "    leaves = [node for node in graph.nodes if graph.out_degree(node) == 0]\n",
    "    all_paths = [nx.shortest_path(graph, source=\"997\", target=leaf) for leaf in leaves if nx.has_path(graph, \"997\", leaf)]\n",
    "    from collections import Counter\n",
    "    counts = Counter()\n",
    "    for path in all_paths:\n",
    "        counts.update(path)\n",
    "    ranked = [node for node, _ in counts.most_common()]\n",
    "    selected = set()\n",
    "    for node in ranked:\n",
    "        descendants = nx.descendants(graph, node)\n",
    "        if not any(d in selected for d in descendants):\n",
    "            selected.add(node)\n",
    "        if len(selected) >= n_regions:\n",
    "            break\n",
    "    return list(selected)\n",
    "\n",
    "collapsed_region_ids = collapse_tree_to_n(G, target_n_regions)\n",
    "\n",
    "\n",
    "# === MAP ALL STRUCTURE IDs TO THEIR COLLAPSED TARGET REGION ===\n",
    "structure_to_target = {}\n",
    "for _, row in region_table.iterrows():\n",
    "    sid = str(row[\"id\"])\n",
    "    path = row[\"structure_id_path\"].strip(\"/\").split(\"/\")\n",
    "    for node in reversed(path):\n",
    "        if node in collapsed_region_ids:\n",
    "            structure_to_target[sid] = node\n",
    "            break\n",
    "\n",
    "# === LOAD AND MAP DFF DATA FROM ALL MICE ===\n",
    "df_by_mouse = pd.read_excel(input_excel, sheet_name=None)\n",
    "matrix_data = {}\n",
    "\n",
    "for sheet_name, df_mouse in df_by_mouse.items():\n",
    "    if sheet_name.lower() == \"summary\" or \"structure_id_path\" not in df_mouse.columns:\n",
    "        continue\n",
    "\n",
    "    region_means = {}\n",
    "    for _, row in df_mouse.iterrows():\n",
    "        path = row[\"structure_id_path\"].strip(\"/\").split(\"/\")\n",
    "        leaf_id = path[-1]\n",
    "        target = structure_to_target.get(leaf_id)\n",
    "        if target:\n",
    "            region_means.setdefault(target, []).append(row[\"mean_dff\"])\n",
    "\n",
    "    averaged = {rid: sum(vals) / len(vals) for rid, vals in region_means.items()}\n",
    "    matrix_data[sheet_name] = averaged\n",
    "\n",
    "\n",
    "# === ASSEMBLE WIDE MATRIX ===\n",
    "df_matrix = pd.DataFrame(matrix_data).T  # Mice × Regions\n",
    "available_regions = [rid for rid in collapsed_region_ids if rid in df_matrix.columns]\n",
    "missing = set(collapsed_region_ids) - set(df_matrix.columns)\n",
    "print(f\"[INFO] {len(missing)} regions had no data and were excluded.\")\n",
    "df_matrix = df_matrix[available_regions]\n",
    "df_matrix = df_matrix.T  # Regions × Mice\n",
    "\n",
    "# === ADD REGION INFO: acronym, name, depth ===\n",
    "id_to_meta = region_table.set_index(\"id\")[[\"acronym\", \"name\", \"structure_id_path\"]].astype(str)\n",
    "df_matrix[\"acronym\"] = df_matrix.index.map(lambda x: id_to_meta.loc[int(x), \"acronym\"] if int(x) in id_to_meta.index else \"\")\n",
    "df_matrix[\"name\"] = df_matrix.index.map(lambda x: id_to_meta.loc[int(x), \"name\"] if int(x) in id_to_meta.index else \"\")\n",
    "df_matrix[\"depth\"] = df_matrix.index.map(lambda x: len(id_to_meta.loc[int(x), \"structure_id_path\"].strip(\"/\").split(\"/\")) if int(x) in id_to_meta.index else None)\n",
    "df_matrix.insert(0, \"region_id\", df_matrix.index)\n",
    "\n",
    "# === ADD CATEGORY FROM pe_grouped.csv ===\n",
    "category_df = pd.read_csv(category_csv)\n",
    "category_df[\"abbrev\"] = category_df[\"abbrev\"].astype(str)\n",
    "category_df[\"name\"] = category_df[\"name\"].astype(str)\n",
    "\n",
    "df_matrix[\"category\"] = df_matrix[\"acronym\"].map(dict(zip(category_df[\"abbrev\"], category_df[\"category\"])))\n",
    "unmatched = df_matrix[\"category\"].isna()\n",
    "df_matrix.loc[unmatched, \"category\"] = df_matrix.loc[unmatched, \"name\"].map(\n",
    "    dict(zip(category_df[\"name\"], category_df[\"category\"]))\n",
    ")\n",
    "\n",
    "# === SAVE ===\n",
    "df_matrix.to_excel(output_file, index=False)\n",
    "print(f\"Final matrix saved to:\\n{output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f15b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "354\tMedulla\t/997/8/343/1065/354/\n",
    "771\tPons\t/997/8/343/1065/771/\n",
    "1097\tHypothalamus\t/997/8/343/1129/1097/\n",
    "549\tThalamus\t/997/8/343/1129/549/\n",
    "313\tMidbrain\t/997/8/343/313/\n",
    "512\tCerebellum\t/997/8/512/\n",
    "695\tCortical plate\t/997/8/567/688/695/\n",
    "703\tCortical subplate\t/997/8/567/688/703/\n",
    "803\tPallidum\t/997/8/567/623/803/\n",
    "477\tStriatum\t/997/8/567/623/477/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c56410d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Reduced to 134 non-overlapping regions.\n",
      "[INFO] 18 collapsed regions had no data.\n",
      " Final matrix saved to:\n",
      "Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\PE_mapping\\processed_data\\dff_downsampled\\colapsed_dff_cleaned_210.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "\n",
    "# === CONFIG ===\n",
    "structures_csv = r\"Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\code\\cfos_preprocessing\\allen_mouse_10um_v1.2\\structures.csv\"\n",
    "input_excel = r\"Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\PE_mapping\\processed_data\\dff_downsampled\\mean_dff_per_region_by_mouse_brainmapper.xlsx\"\n",
    "output_file = r\"Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\PE_mapping\\processed_data\\dff_downsampled\\colapsed_dff_cleaned_210.xlsx\"\n",
    "target_n_regions = 210\n",
    "\n",
    "# === LOAD REGION HIERARCHY ===\n",
    "region_table = pd.read_csv(structures_csv)\n",
    "region_table['structure_id_path'] = region_table['structure_id_path'].astype(str)\n",
    "id_to_path = region_table.set_index(\"id\")[\"structure_id_path\"].astype(str).to_dict()\n",
    "\n",
    "# Build anatomical graph\n",
    "G = nx.DiGraph()\n",
    "for _, row in region_table.iterrows():\n",
    "    path = row[\"structure_id_path\"].strip(\"/\").split(\"/\")\n",
    "    for i in range(len(path) - 1):\n",
    "        G.add_edge(path[i], path[i + 1])\n",
    "\n",
    "# Collapse to 130 nodes\n",
    "def collapse_tree_to_n(graph, n_regions):\n",
    "    leaves = [node for node in graph.nodes if graph.out_degree(node) == 0]\n",
    "    all_paths = [nx.shortest_path(graph, source=\"997\", target=leaf) for leaf in leaves if nx.has_path(graph, \"997\", leaf)]\n",
    "    from collections import Counter\n",
    "    counts = Counter()\n",
    "    for path in all_paths:\n",
    "        counts.update(path)\n",
    "    ranked = [node for node, _ in counts.most_common()]\n",
    "    selected = set()\n",
    "    for node in ranked:\n",
    "        descendants = nx.descendants(graph, node)\n",
    "        if not any(d in selected for d in descendants):\n",
    "            selected.add(node)\n",
    "        if len(selected) >= n_regions:\n",
    "            break\n",
    "    return list(selected)\n",
    "\n",
    "collapsed_region_ids = collapse_tree_to_n(G, target_n_regions)\n",
    "\n",
    "# === REMOVE REDUNDANT PARENT REGIONS ===\n",
    "collapsed_with_paths = [(rid, id_to_path.get(int(rid), \"\")) for rid in collapsed_region_ids]\n",
    "\n",
    "def is_subpath(p1, p2):\n",
    "    return p2.startswith(p1) and p1 != p2\n",
    "\n",
    "filtered_regions = []\n",
    "paths = [p for _, p in collapsed_with_paths]\n",
    "for i, (rid1, path1) in enumerate(collapsed_with_paths):\n",
    "    if any(is_subpath(path1, p2) for j, p2 in enumerate(paths) if j != i):\n",
    "        continue\n",
    "    filtered_regions.append(rid1)\n",
    "\n",
    "collapsed_region_ids = filtered_regions\n",
    "print(f\"[INFO] Reduced to {len(collapsed_region_ids)} non-overlapping regions.\")\n",
    "\n",
    "# === MAP STRUCTURE TO COLLAPSED REGIONS ===\n",
    "structure_to_target = {}\n",
    "for _, row in region_table.iterrows():\n",
    "    sid = str(row[\"id\"])\n",
    "    path = row[\"structure_id_path\"].strip(\"/\").split(\"/\")\n",
    "    for node in reversed(path):\n",
    "        if node in collapsed_region_ids:\n",
    "            structure_to_target[sid] = node\n",
    "            break\n",
    "\n",
    "# === LOAD MOUSE DFF ===\n",
    "df_by_mouse = pd.read_excel(input_excel, sheet_name=None)\n",
    "matrix_data = {}\n",
    "\n",
    "for sheet_name, df_mouse in df_by_mouse.items():\n",
    "    if sheet_name.lower() == \"summary\" or \"structure_id_path\" not in df_mouse.columns:\n",
    "        continue\n",
    "    region_means = {}\n",
    "    for _, row in df_mouse.iterrows():\n",
    "        path = row[\"structure_id_path\"].strip(\"/\").split(\"/\")\n",
    "        leaf_id = path[-1]\n",
    "        target = structure_to_target.get(leaf_id)\n",
    "        if target:\n",
    "            region_means.setdefault(target, []).append(row[\"mean_dff\"])\n",
    "    averaged = {rid: sum(vals) / len(vals) for rid, vals in region_means.items()}\n",
    "    matrix_data[sheet_name] = averaged\n",
    "\n",
    "# === FINAL MATRIX ===\n",
    "df_matrix = pd.DataFrame(matrix_data).T\n",
    "available_regions = [rid for rid in collapsed_region_ids if rid in df_matrix.columns]\n",
    "missing = set(collapsed_region_ids) - set(df_matrix.columns)\n",
    "print(f\"[INFO] {len(missing)} collapsed regions had no data.\")\n",
    "\n",
    "df_matrix = df_matrix[available_regions].T\n",
    "df_matrix[\"region_id\"] = df_matrix.index.astype(int)\n",
    "\n",
    "# Add structure metadata\n",
    "id_meta = region_table.set_index(\"id\")[[\"acronym\", \"name\", \"structure_id_path\"]].astype(str)\n",
    "df_matrix[\"acronym\"] = df_matrix[\"region_id\"].map(lambda x: id_meta.loc[x, \"acronym\"] if x in id_meta.index else \"\")\n",
    "df_matrix[\"name\"] = df_matrix[\"region_id\"].map(lambda x: id_meta.loc[x, \"name\"] if x in id_meta.index else \"\")\n",
    "df_matrix[\"structure_id_path\"] = df_matrix[\"region_id\"].map(lambda x: id_meta.loc[x, \"structure_id_path\"] if x in id_meta.index else \"\")\n",
    "df_matrix[\"depth\"] = df_matrix[\"structure_id_path\"].map(lambda p: len(p.strip(\"/\").split(\"/\")))\n",
    "\n",
    "# Add anatomical category based on path prefix\n",
    "category_map = {\n",
    "    \"Medulla\": \"/997/8/343/1065/354/\",\n",
    "    \"Pons\": \"/997/8/343/1065/771/\",\n",
    "    \"Hypothalamus\": \"/997/8/343/1129/1097/\",\n",
    "    \"Thalamus\": \"/997/8/343/1129/549/\",\n",
    "    \"Midbrain\": \"/997/8/343/313/\",\n",
    "    \"Cerebellum\": \"/997/8/512/\",\n",
    "    \"Cortical plate\": \"/997/8/567/688/695/\",\n",
    "    \"Cortical subplate\": \"/997/8/567/688/703/\",\n",
    "    \"Pallidum\": \"/997/8/567/623/803/\",\n",
    "    \"Striatum\": \"/997/8/567/623/477/\"\n",
    "}\n",
    "\n",
    "def assign_category(path):\n",
    "    for cat, prefix in category_map.items():\n",
    "        if path.startswith(prefix):\n",
    "            return cat\n",
    "    return \"Other\"\n",
    "\n",
    "df_matrix[\"category\"] = df_matrix[\"structure_id_path\"].map(assign_category)\n",
    "\n",
    "# Reorder columns\n",
    "meta_cols = [\"region_id\", \"acronym\", \"name\", \"structure_id_path\", \"depth\", \"category\"]\n",
    "df_matrix = df_matrix[meta_cols + [col for col in df_matrix.columns if col not in meta_cols]]\n",
    "\n",
    "# === SAVE ===\n",
    "df_matrix.to_excel(output_file, index=False)\n",
    "print(f\" Final matrix saved to:\\n{output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c733449a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped 0 regions to collapsed parents.\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Saved to: Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\PE_mapping\\processed_data\\dff_downsampled\\child_to_collapsed_map.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === CONFIG ===\n",
    "structures_path = r\"Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\code\\cfos_preprocessing\\allen_mouse_10um_v1.2\\structures.csv\"\n",
    "output_csv = r\"Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\PE_mapping\\processed_data\\dff_downsampled\\child_to_collapsed_map.csv\"\n",
    "\n",
    "# === Load region hierarchy ===\n",
    "region_table = pd.read_csv(structures_path)\n",
    "region_table[\"structure_id_path\"] = region_table[\"structure_id_path\"].astype(str)\n",
    "\n",
    "id_to_path = region_table.set_index(\"id\")[\"structure_id_path\"].astype(str).to_dict()\n",
    "id_to_name = region_table.set_index(\"id\")[\"name\"].astype(str).to_dict()\n",
    "\n",
    "# === Define the 10 collapsed categories (based on root IDs) ===\n",
    "collapsed_region_ids = [\n",
    "    354,   # Medulla\n",
    "    771,   # Pons\n",
    "    1097,  # Hypothalamus\n",
    "    549,   # Thalamus\n",
    "    313,   # Midbrain\n",
    "    512,   # Cerebellum\n",
    "    695,   # Cortical plate\n",
    "    703,   # Cortical subplate\n",
    "    803,   # Pallidum\n",
    "    477    # Striatum\n",
    "]\n",
    "collapsed_region_ids = list(map(str, collapsed_region_ids))\n",
    "\n",
    "# === Build structure_id_path mapping ===\n",
    "collapsed_paths = {cid: id_to_path[int(cid)] for cid in collapsed_region_ids}\n",
    "\n",
    "# === Map each region to its collapsed parent ===\n",
    "mapping_rows = []\n",
    "for sid, path in id_to_path.items():\n",
    "    assigned_parent = None\n",
    "    for parent_id, parent_path in collapsed_paths.items():\n",
    "        parent_path_clean = parent_path.strip(\"/\")\n",
    "        if path.startswith(parent_path_clean + \"/\") or path == parent_path_clean:\n",
    "            assigned_parent = parent_id\n",
    "            break\n",
    "\n",
    "    if assigned_parent:\n",
    "        mapping_rows.append({\n",
    "            \"child_region_id\": sid,\n",
    "            \"child_region_name\": id_to_name.get(int(sid), \"\"),\n",
    "            \"child_structure_id_path\": path,\n",
    "            \"collapsed_region_id\": assigned_parent,\n",
    "            \"collapsed_region_name\": id_to_name.get(int(assigned_parent), \"\")\n",
    "        })\n",
    "\n",
    "df_map = pd.DataFrame(mapping_rows)\n",
    "\n",
    "# === Save or display ===\n",
    "print(f\"Mapped {len(df_map)} regions to collapsed parents.\")\n",
    "print(df_map.head(10))\n",
    "\n",
    "df_map.to_csv(output_csv, index=False)\n",
    "print(f\"Saved to: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "954cfb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsed matrix saved to:\n",
      "Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\PE_mapping\\processed_data\\dff_downsampled\\final_collapsed_matrix.xlsx\n",
      "Collapse log with ΔF/F contributions saved to:\n",
      "Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\PE_mapping\\processed_data\\dff_downsampled\\dff_collapsing_log.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# === CONFIG ===\n",
    "structures_path = r\"Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\code\\cfos_preprocessing\\allen_mouse_10um_v1.2\\structures.csv\"\n",
    "input_excel = r\"Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\PE_mapping\\processed_data\\dff_downsampled\\mean_dff_per_region_by_mouse_brainmapper.xlsx\"\n",
    "output_matrix = r\"Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\PE_mapping\\processed_data\\dff_downsampled\\final_collapsed_matrix.xlsx\"\n",
    "output_log = r\"Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\PE_mapping\\processed_data\\dff_downsampled\\dff_collapsing_log.csv\"\n",
    "TARGET_N = 160\n",
    "\n",
    "# === Load hierarchy ===\n",
    "region_table = pd.read_csv(structures_path)\n",
    "region_table[\"structure_id_path\"] = region_table[\"structure_id_path\"].astype(str)\n",
    "id_to_path = region_table.set_index(\"id\")[\"structure_id_path\"].astype(str).to_dict()\n",
    "id_to_name = region_table.set_index(\"id\")[\"name\"].astype(str).to_dict()\n",
    "\n",
    "# === Build graph from structure_id_path ===\n",
    "G = nx.DiGraph()\n",
    "for _, row in region_table.iterrows():\n",
    "    path = row[\"structure_id_path\"].strip(\"/\").split(\"/\")\n",
    "    for i in range(len(path) - 1):\n",
    "        G.add_edge(path[i], path[i + 1])\n",
    "\n",
    "# === Collapse function ===\n",
    "def collapse_tree_to_n(graph, n):\n",
    "    leaves = [n for n in graph.nodes if graph.out_degree(n) == 0]\n",
    "    all_paths = [nx.shortest_path(graph, source=\"997\", target=leaf)\n",
    "                 for leaf in leaves if nx.has_path(graph, \"997\", leaf)]\n",
    "    from collections import Counter\n",
    "    counts = Counter()\n",
    "    for path in all_paths:\n",
    "        counts.update(path)\n",
    "    ranked = [node for node, _ in counts.most_common()]\n",
    "    selected = set()\n",
    "    for node in ranked:\n",
    "        descendants = nx.descendants(graph, node)\n",
    "        if not any(d in selected for d in descendants):\n",
    "            selected.add(node)\n",
    "        if len(selected) >= n:\n",
    "            break\n",
    "    return list(selected)\n",
    "\n",
    "collapsed_region_ids = collapse_tree_to_n(G, TARGET_N)\n",
    "\n",
    "# === Map child → parent ===\n",
    "structure_to_collapsed = {}\n",
    "for sid, path in id_to_path.items():\n",
    "    parts = path.strip(\"/\").split(\"/\")\n",
    "    for node in reversed(parts):\n",
    "        if node in collapsed_region_ids:\n",
    "            structure_to_collapsed[str(sid)] = node\n",
    "            break\n",
    "\n",
    "# === Load per-mouse DFF ===\n",
    "df_by_mouse = pd.read_excel(input_excel, sheet_name=None)\n",
    "matrix_data = defaultdict(dict)\n",
    "log_rows = []\n",
    "\n",
    "for sheet_name, df_mouse in df_by_mouse.items():\n",
    "    if sheet_name.lower() == \"summary\" or \"structure_id_path\" not in df_mouse.columns:\n",
    "        continue\n",
    "    mouse_id = sheet_name\n",
    "    temp_assignments = defaultdict(list)\n",
    "\n",
    "    for _, row in df_mouse.iterrows():\n",
    "        path = row[\"structure_id_path\"].strip(\"/\").split(\"/\")\n",
    "        region_id = path[-1]\n",
    "        collapsed_id = structure_to_collapsed.get(region_id)\n",
    "        if collapsed_id:\n",
    "            temp_assignments[collapsed_id].append((region_id, row[\"mean_dff\"]))\n",
    "\n",
    "            # Logging for traceability\n",
    "            log_rows.append({\n",
    "                \"mouse\": mouse_id,\n",
    "                \"collapsed_region_id\": collapsed_id,\n",
    "                \"collapsed_region_name\": id_to_name.get(int(collapsed_id), \"\"),\n",
    "                \"child_region_id\": region_id,\n",
    "                \"child_region_name\": id_to_name.get(int(region_id), \"\"),\n",
    "                \"child_structure_id_path\": row[\"structure_id_path\"],\n",
    "                \"mean_dff_contribution\": row[\"mean_dff\"]\n",
    "            })\n",
    "\n",
    "    for cid, values in temp_assignments.items():\n",
    "        mean_val = sum(v for _, v in values) / len(values)\n",
    "        matrix_data[mouse_id][cid] = mean_val\n",
    "\n",
    "# === Build matrix\n",
    "df_matrix = pd.DataFrame(matrix_data).T\n",
    "df_matrix.index.name = \"mouse\"\n",
    "df_matrix.columns.name = \"collapsed_region_id\"\n",
    "df_matrix = df_matrix.T\n",
    "df_matrix[\"region_id\"] = df_matrix.index.astype(int)\n",
    "df_matrix[\"name\"] = df_matrix[\"region_id\"].map(lambda x: id_to_name.get(x, \"\"))\n",
    "df_matrix[\"structure_id_path\"] = df_matrix[\"region_id\"].map(lambda x: id_to_path.get(x, \"\"))\n",
    "df_matrix[\"depth\"] = df_matrix[\"structure_id_path\"].map(lambda p: len(p.strip(\"/\").split(\"/\")))\n",
    "\n",
    "# Move metadata columns to front\n",
    "meta_cols = [\"region_id\", \"name\", \"structure_id_path\", \"depth\"]\n",
    "df_matrix = df_matrix[meta_cols + [col for col in df_matrix.columns if col not in meta_cols]]\n",
    "\n",
    "# === Save\n",
    "df_matrix.to_excel(output_matrix, index=False)\n",
    "print(f\"Collapsed matrix saved to:\\n{output_matrix}\")\n",
    "\n",
    "log_df = pd.DataFrame(log_rows)\n",
    "log_df.to_csv(output_log, index=False)\n",
    "print(f\"Collapse log with ΔF/F contributions saved to:\\n{output_log}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24604412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix with mean, std, sem saved to:\n",
      "Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\PE_mapping\\processed_data\\dff_downsampled\\final_collapsed_matrix_2.xlsx\n",
      "Detailed ΔF/F log saved to:\n",
      "Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\PE_mapping\\processed_data\\dff_downsampled\\dff_collapsing_log_2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# === CONFIG ===\n",
    "structures_path = r\"Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\code\\cfos_preprocessing\\allen_mouse_10um_v1.2\\structures.csv\"\n",
    "input_excel = r\"Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\PE_mapping\\processed_data\\dff_downsampled\\mean_dff_per_region_by_mouse_brainmapper.xlsx\"\n",
    "output_excel = r\"Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\PE_mapping\\processed_data\\dff_downsampled\\final_collapsed_matrix_2.xlsx\"\n",
    "output_log = r\"Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\PE_mapping\\processed_data\\dff_downsampled\\dff_collapsing_log_2.csv\"\n",
    "TARGET_N = 160\n",
    "# === Load Allen structure data ===\n",
    "region_table = pd.read_csv(structures_path)\n",
    "region_table[\"structure_id_path\"] = region_table[\"structure_id_path\"].astype(str)\n",
    "id_to_acronym = region_table.set_index(\"id\")[\"acronym\"].astype(str).to_dict()\n",
    "id_to_path = region_table.set_index(\"id\")[\"structure_id_path\"].astype(str).to_dict()\n",
    "id_to_name = region_table.set_index(\"id\")[\"name\"].astype(str).to_dict()\n",
    "\n",
    "# === Build anatomical hierarchy graph ===\n",
    "G = nx.DiGraph()\n",
    "for _, row in region_table.iterrows():\n",
    "    path = row[\"structure_id_path\"].strip(\"/\").split(\"/\")\n",
    "    for i in range(len(path) - 1):\n",
    "        G.add_edge(path[i], path[i + 1])\n",
    "\n",
    "# === Collapse region selection ===\n",
    "def collapse_tree_to_n(graph, n):\n",
    "    leaves = [n for n in graph.nodes if graph.out_degree(n) == 0]\n",
    "    all_paths = [nx.shortest_path(graph, source=\"997\", target=leaf)\n",
    "                 for leaf in leaves if nx.has_path(graph, \"997\", leaf)]\n",
    "    from collections import Counter\n",
    "    counts = Counter()\n",
    "    for path in all_paths:\n",
    "        counts.update(path)\n",
    "    ranked = [node for node, _ in counts.most_common()]\n",
    "    selected = set()\n",
    "    for node in ranked:\n",
    "        descendants = nx.descendants(graph, node)\n",
    "        if not any(d in selected for d in descendants):\n",
    "            selected.add(node)\n",
    "        if len(selected) >= n:\n",
    "            break\n",
    "    return list(selected)\n",
    "\n",
    "collapsed_region_ids = collapse_tree_to_n(G, TARGET_N)\n",
    "\n",
    "# === Map child → collapsed parent ===\n",
    "structure_to_collapsed = {}\n",
    "for sid, path in id_to_path.items():\n",
    "    parts = path.strip(\"/\").split(\"/\")\n",
    "    for node in reversed(parts):\n",
    "        if node in collapsed_region_ids:\n",
    "            structure_to_collapsed[str(sid)] = node\n",
    "            break\n",
    "\n",
    "# === Process all mice ===\n",
    "df_by_mouse = pd.read_excel(input_excel, sheet_name=None)\n",
    "mean_data = defaultdict(dict)\n",
    "std_data = defaultdict(dict)\n",
    "sem_data = defaultdict(dict)\n",
    "log_rows = []\n",
    "\n",
    "for sheet_name, df_mouse in df_by_mouse.items():\n",
    "    if sheet_name.lower() == \"summary\" or \"structure_id_path\" not in df_mouse.columns:\n",
    "        continue\n",
    "    mouse_id = sheet_name\n",
    "    temp_assignments = defaultdict(list)\n",
    "\n",
    "    for _, row in df_mouse.iterrows():\n",
    "        path = row[\"structure_id_path\"].strip(\"/\").split(\"/\")\n",
    "        region_id = path[-1]\n",
    "        collapsed_id = structure_to_collapsed.get(region_id)\n",
    "        if collapsed_id:\n",
    "            temp_assignments[collapsed_id].append(row[\"mean_dff\"])\n",
    "            log_rows.append({\n",
    "                \"mouse\": mouse_id,\n",
    "                \"collapsed_region_id\": collapsed_id,\n",
    "                \"collapsed_region_name\": id_to_name.get(int(collapsed_id), \"\"),\n",
    "                \"child_region_id\": region_id,\n",
    "                \"child_region_name\": id_to_name.get(int(region_id), \"\"),\n",
    "                \"child_structure_id_path\": row[\"structure_id_path\"],\n",
    "                \"mean_dff_contribution\": row[\"mean_dff\"]\n",
    "            })\n",
    "\n",
    "    for cid, values in temp_assignments.items():\n",
    "        arr = np.array(values, dtype=float)\n",
    "        mean_data[mouse_id][cid] = np.mean(arr)\n",
    "        std_data[mouse_id][cid] = np.std(arr, ddof=1) if len(arr) > 1 else 0.0\n",
    "        sem_data[mouse_id][cid] = std_data[mouse_id][cid] / np.sqrt(len(arr)) if len(arr) > 1 else 0.0\n",
    "\n",
    "# === Format outputs\n",
    "def build_df(data_dict, id_to_name, id_to_path, id_to_acronym):\n",
    "    df = pd.DataFrame(data_dict).T\n",
    "    df.index.name = \"mouse\"\n",
    "    df.columns.name = \"collapsed_region_id\"\n",
    "    df = df.T\n",
    "    df[\"region_id\"] = df.index.astype(int)\n",
    "    df[\"name\"] = df[\"region_id\"].map(lambda x: id_to_name.get(x, \"\"))\n",
    "    df[\"acronym\"] = df[\"region_id\"].map(lambda x: id_to_acronym.get(x, \"\"))\n",
    "    df[\"structure_id_path\"] = df[\"region_id\"].map(lambda x: id_to_path.get(x, \"\"))\n",
    "    df[\"depth\"] = df[\"structure_id_path\"].map(lambda p: len(p.strip(\"/\").split(\"/\")))\n",
    "    meta_cols = [\"region_id\", \"name\", \"acronym\", \"structure_id_path\", \"depth\"]\n",
    "    return df[meta_cols + [col for col in df.columns if col not in meta_cols]]\n",
    "\n",
    "df_mean = build_df(mean_data, id_to_name, id_to_path, id_to_acronym)\n",
    "df_std = build_df(std_data, id_to_name, id_to_path, id_to_acronym)\n",
    "df_sem = build_df(sem_data, id_to_name, id_to_path, id_to_acronym)\n",
    "\n",
    "# === Export all\n",
    "with pd.ExcelWriter(output_excel) as writer:\n",
    "    df_mean.to_excel(writer, sheet_name=\"mean_dff\", index=False)\n",
    "    df_std.to_excel(writer, sheet_name=\"std_dff\", index=False)\n",
    "    df_sem.to_excel(writer, sheet_name=\"sem_dff\", index=False)\n",
    "print(f\"Matrix with mean, std, sem saved to:\\n{output_excel}\")\n",
    "\n",
    "# Save log\n",
    "pd.DataFrame(log_rows).to_csv(output_log, index=False)\n",
    "print(f\"Detailed ΔF/F log saved to:\\n{output_log}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainglobe_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
