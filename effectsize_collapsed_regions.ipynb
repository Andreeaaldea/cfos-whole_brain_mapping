{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a4d4bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a786ac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- CONFIG ----\n",
    "collapsed_excel = r\"Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\PE_mapping\\processed_data\\den_collapsed_matrix.xlsx\"\n",
    "sheet_name      = \"mean_cells_per_mm3\"\n",
    "out_dir         = r\"Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\PE_mapping\\processed_data\\ES_plots_normalized\"\n",
    "out_excel       = str(Path(out_dir) / \"effect_sizes_PE_vs_CT_by_hemi.xlsx\")\n",
    "normalization   = \"brain_mean\"       # \"none\" or \"brain_mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd6849c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If names don’t encode genotype/condition cleanly, provide a mapping CSV:\n",
    "mapping_csv = None  # CSV with columns: mouse_base, genotype (WT/Shank3), condition (PE/CT)\n",
    "\n",
    "Path(out_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fb8b61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def extract_base_and_hemi(col):\n",
    "    m = re.match(r\"^(?P<base>.+)_(?P<hemi>[LR])$\", col)\n",
    "    if not m:\n",
    "        return None, None\n",
    "    return m.group(\"base\"), m.group(\"hemi\")\n",
    "\n",
    "def parse_labels(base_name):\n",
    "    s = base_name.lower()\n",
    "    genotype = \"WT\" if \"wt\" in s else (\"Shank3\" if \"shank3\" in s else None)\n",
    "    if re.search(r\"\\bpe\\b\", s):\n",
    "        condition = \"PE\"\n",
    "    elif re.search(r\"\\b(ct|ctrl|control)\\b\", s):\n",
    "        condition = \"CT\"\n",
    "    else:\n",
    "        toks = re.split(r\"[_\\-\\s]+\", s)\n",
    "        condition = \"PE\" if \"pe\" in toks else (\"CT\" if any(t in {\"ct\",\"ctrl\",\"control\"} for t in toks) else None)\n",
    "    return genotype, condition\n",
    "\n",
    "def cohens_d(x, y):\n",
    "    x = np.asarray(x, float); y = np.asarray(y, float)\n",
    "    x = x[np.isfinite(x)]; y = y[np.isfinite(y)]\n",
    "    n1, n2 = len(x), len(y)\n",
    "    if n1 < 2 or n2 < 2:\n",
    "        return np.nan, np.nan, np.nan, n1, n2, np.nan, np.nan, np.nan, np.nan\n",
    "    m1, m2 = x.mean(), y.mean()\n",
    "    s1, s2 = x.std(ddof=1), y.std(ddof=1)\n",
    "    sp2 = (((n1-1)*s1**2) + ((n2-1)*s2**2)) / (n1+n2-2)\n",
    "    sp = sqrt(sp2) if sp2 > 0 else np.nan\n",
    "    d = (m1 - m2) / sp if sp > 0 else np.nan\n",
    "    var_d = (n1+n2)/(n1*n2) + (d**2)/(2*(n1+n2-2)) if np.isfinite(d) else np.nan\n",
    "    se_d = sqrt(var_d) if np.isfinite(var_d) and var_d >= 0 else np.nan\n",
    "    ci_lo = d - 1.96*se_d if np.isfinite(se_d) else np.nan\n",
    "    ci_hi = d + 1.96*se_d if np.isfinite(se_d) else np.nan\n",
    "    return d, ci_lo, ci_hi, n1, n2, m1, m2, s1, s2\n",
    "\n",
    "def hedges_g_from_d(d, n1, n2, ci_lo_d, ci_hi_d):\n",
    "    if not np.isfinite(d) or n1 is None or n2 is None:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    J = 1.0 - 3.0 / (4.0*(n1+n2) - 9.0)\n",
    "    g = J * d\n",
    "    # approximate CI by scaling d's CI (common practice for quick reporting)\n",
    "    return g, J*ci_lo_d, J*ci_hi_d\n",
    "\n",
    "def build_registry(df, mapping_csv=None):\n",
    "    meta_candidates = [\"region_id\",\"acronym\",\"name\",\"structure_id_path\",\"depth\",\"structure_name\"]\n",
    "    meta_cols = [c for c in meta_candidates if c in df.columns]\n",
    "    value_cols = [c for c in df.columns if c not in meta_cols and pd.api.types.is_numeric_dtype(df[c])]\n",
    "    rows = []\n",
    "    for c in value_cols:\n",
    "        base, hemi = extract_base_and_hemi(c)\n",
    "        if base is None:\n",
    "            continue\n",
    "        rows.append({\"col\": c, \"base\": base, \"hemi\": hemi})\n",
    "    reg = pd.DataFrame(rows)\n",
    "    if mapping_csv is None:\n",
    "        reg[[\"genotype\",\"condition\"]] = reg[\"base\"].apply(lambda b: pd.Series(parse_labels(b)))\n",
    "    else:\n",
    "        mp = pd.read_csv(mapping_csv)\n",
    "        mp[\"mouse_base\"] = mp[\"mouse_base\"].astype(str)\n",
    "        reg = reg.merge(mp.rename(columns={\"mouse_base\":\"base\"}), on=\"base\", how=\"left\")\n",
    "    reg = reg[reg[\"genotype\"].isin([\"WT\",\"Shank3\"]) & reg[\"condition\"].isin([\"PE\",\"CT\"])]\n",
    "    return reg, meta_cols, value_cols\n",
    "\n",
    "def normalize_brain_mean(df, reg):\n",
    "    \"\"\"Divide each mouse’s L/R columns by that mouse’s across-region mean (using both hemispheres).\"\"\"\n",
    "    df = df.copy()\n",
    "    for base in sorted(reg[\"base\"].unique()):\n",
    "        cols = []\n",
    "        sub = reg[reg[\"base\"] == base]\n",
    "        if \"L\" in set(sub[\"hemi\"]):\n",
    "            cols.append(sub[sub[\"hemi\"]==\"L\"][\"col\"].iloc[0])\n",
    "        if \"R\" in set(sub[\"hemi\"]):\n",
    "            cols.append(sub[sub[\"hemi\"]==\"R\"][\"col\"].iloc[0])\n",
    "        cols = [c for c in cols if c in df.columns]\n",
    "        if not cols:\n",
    "            continue\n",
    "        denom = pd.concat([df[c] for c in cols], axis=1).mean(axis=1)  # mean across hemispheres, per region\n",
    "        # Use overall mean across regions as the scaling factor for this mouse\n",
    "        scale = denom.mean(skipna=True)\n",
    "        if np.isfinite(scale) and scale != 0:\n",
    "            for c in cols:\n",
    "                df[c] = df[c] / scale\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99c06cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Load data and (optionally) normalize ----\n",
    "df = pd.read_excel(collapsed_excel, sheet_name=sheet_name)\n",
    "reg, meta_cols, value_cols = build_registry(df, mapping_csv)\n",
    "\n",
    "if normalization == \"brain_mean\":\n",
    "    df = normalize_brain_mean(df, reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "498c4014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Quick plots (per genotype) ----\n",
    "def make_scatter(df, cols_L, cols_R, title, outpath):\n",
    "    plt.figure()\n",
    "    # mean across mice for a region per hemi\n",
    "    x = df[cols_L].mean(axis=1, skipna=True)\n",
    "    y = df[cols_R].mean(axis=1, skipna=True)\n",
    "    plt.scatter(x, y, alpha=0.7)\n",
    "    mn = np.nanmin([x.min(), y.min()])\n",
    "    mx = np.nanmax([x.max(), y.max()])\n",
    "    plt.plot([mn, mx], [mn, mx])\n",
    "    plt.xlabel(\"Left (mean across mice)\")\n",
    "    plt.ylabel(\"Right (mean across mice)\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "def make_delta_hist(df, cols_L, cols_R, title, outpath):\n",
    "    plt.figure()\n",
    "    # build per-mouse deltas then stack (one big distribution)\n",
    "    deltas = []\n",
    "    for cL, cR in zip(cols_L, cols_R):\n",
    "        if cL in df.columns and cR in df.columns:\n",
    "            d = (df[cR] - df[cL]).to_numpy(dtype=float)\n",
    "            d = d[np.isfinite(d)]\n",
    "            deltas.append(d)\n",
    "    if deltas:\n",
    "        all_d = np.concatenate(deltas)\n",
    "        plt.hist(all_d, bins=40)\n",
    "    plt.xlabel(\"Delta (R - L)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "for genotype in [\"WT\",\"Shank3\"]:\n",
    "    for condition in [\"PE\",\"CT\"]:\n",
    "        sub = reg[(reg[\"genotype\"]==genotype) & (reg[\"condition\"]==condition)]\n",
    "        # Collect matching L/R columns (by base)\n",
    "        bases = sorted(sub[\"base\"].unique())\n",
    "        cols_L = []; cols_R = []\n",
    "        for b in bases:\n",
    "            cL = sub[(sub[\"base\"]==b) & (sub[\"hemi\"]==\"L\")][\"col\"]\n",
    "            cR = sub[(sub[\"base\"]==b) & (sub[\"hemi\"]==\"R\")][\"col\"]\n",
    "            if len(cL)==1: cols_L.append(cL.iloc[0])\n",
    "            if len(cR)==1: cols_R.append(cR.iloc[0])\n",
    "        if cols_L and cols_R:\n",
    "            make_scatter(df, cols_L, cols_R,\n",
    "                         f\"{genotype} {condition}: Left vs Right (region means over mice)\",\n",
    "                         str(Path(out_dir)/f\"scatter_{genotype}_{condition}.png\"))\n",
    "            make_delta_hist(df, cols_L, cols_R,\n",
    "                            f\"{genotype} {condition}: Δ (R−L) distribution\",\n",
    "                            str(Path(out_dir)/f\"delta_hist_{genotype}_{condition}.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "614748ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plots to: Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\PE_mapping\\processed_data\\ES_plots_normalized\n",
      "Saved effect sizes to: Y:\\public\\projects\\AnAl_20240405_Neuromod_PE\\PE_mapping\\processed_data\\ES_plots_normalized\\effect_sizes_PE_vs_CT_by_hemi.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ---- Effect sizes (Hedges’ g and Cohen’s d) per region ----\n",
    "def effect_table_for(genotype, hemi):\n",
    "    sub = reg[(reg[\"genotype\"]==genotype) & (reg[\"hemi\"]==hemi)]\n",
    "    pe_cols = sub[sub[\"condition\"]==\"PE\"][\"col\"].tolist()\n",
    "    ct_cols = sub[sub[\"condition\"]==\"CT\"][\"col\"].tolist()\n",
    "    rows = []\n",
    "    for i in range(len(df)):\n",
    "        meta = {k: df.at[i,k] for k in meta_cols if k in df.columns}\n",
    "        x = df.loc[i, pe_cols].to_numpy(dtype=float) if pe_cols else np.array([])\n",
    "        y = df.loc[i, ct_cols].to_numpy(dtype=float) if ct_cols else np.array([])\n",
    "        d, dlo, dhi, n1, n2, m1, m2, s1, s2 = cohens_d(x, y)\n",
    "        g, glo, ghi = hedges_g_from_d(d, n1, n2, dlo, dhi)\n",
    "        rows.append({**meta,\n",
    "                     \"g\": g, \"g_lo\": glo, \"g_hi\": ghi,\n",
    "                     \"d\": d, \"d_lo\": dlo, \"d_hi\": dhi,\n",
    "                     \"n_PE\": n1, \"n_CT\": n2,\n",
    "                     \"mean_PE\": m1, \"mean_CT\": m2,\n",
    "                     \"sd_PE\": s1, \"sd_CT\": s2})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def effect_table_delta_for(genotype):\n",
    "    # require paired L/R per base\n",
    "    pivot = (reg[reg[\"genotype\"]==genotype]\n",
    "             .pivot_table(index=[\"base\",\"condition\"], columns=\"hemi\", values=\"col\", aggfunc=\"first\")\n",
    "             .reset_index())\n",
    "    pe = pivot[pivot[\"condition\"]==\"PE\"].dropna(subset=[\"L\",\"R\"])\n",
    "    ct = pivot[pivot[\"condition\"]==\"CT\"].dropna(subset=[\"L\",\"R\"])\n",
    "    # build per-region per-mouse delta matrices\n",
    "    deltas_pe = [ (df[r[\"R\"]] - df[r[\"L\"]]).to_numpy(dtype=float) for _, r in pe.iterrows() ]\n",
    "    deltas_ct = [ (df[r[\"R\"]] - df[r[\"L\"]]).to_numpy(dtype=float) for _, r in ct.iterrows() ]\n",
    "    rows = []\n",
    "    for i in range(len(df)):\n",
    "        meta = {k: df.at[i,k] for k in meta_cols if k in df.columns}\n",
    "        x = np.array([col[i] for col in deltas_pe], float) if deltas_pe else np.array([])\n",
    "        y = np.array([col[i] for col in deltas_ct], float) if deltas_ct else np.array([])\n",
    "        d, dlo, dhi, n1, n2, m1, m2, s1, s2 = cohens_d(x, y)\n",
    "        g, glo, ghi = hedges_g_from_d(d, n1, n2, dlo, dhi)\n",
    "        rows.append({**meta,\n",
    "                     \"g\": g, \"g_lo\": glo, \"g_hi\": ghi,\n",
    "                     \"d\": d, \"d_lo\": dlo, \"d_hi\": dhi,\n",
    "                     \"n_PE\": n1, \"n_CT\": n2,\n",
    "                     \"mean_PE_delta\": m1, \"mean_CT_delta\": m2,\n",
    "                     \"sd_PE_delta\": s1, \"sd_CT_delta\": s2})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "wt_L  = effect_table_for(\"WT\",\"L\")\n",
    "wt_R  = effect_table_for(\"WT\",\"R\")\n",
    "wt_D  = effect_table_delta_for(\"WT\")\n",
    "sh_L  = effect_table_for(\"Shank3\",\"L\")\n",
    "sh_R  = effect_table_for(\"Shank3\",\"R\")\n",
    "sh_D  = effect_table_delta_for(\"Shank3\")\n",
    "\n",
    "with pd.ExcelWriter(out_excel) as xw:\n",
    "    wt_L.to_excel(xw, sheet_name=f\"WT_L_{normalization}\", index=False)\n",
    "    wt_R.to_excel(xw, sheet_name=f\"WT_R_{normalization}\", index=False)\n",
    "    wt_D.to_excel(xw, sheet_name=f\"WT_Delta_{normalization}\", index=False)\n",
    "    sh_L.to_excel(xw, sheet_name=f\"Shank3_L_{normalization}\", index=False)\n",
    "    sh_R.to_excel(xw, sheet_name=f\"Shank3_R_{normalization}\", index=False)\n",
    "    sh_D.to_excel(xw, sheet_name=f\"Shank3_Delta_{normalization}\", index=False)\n",
    "\n",
    "print(f\"Saved plots to: {out_dir}\")\n",
    "print(f\"Saved effect sizes to: {out_excel}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
